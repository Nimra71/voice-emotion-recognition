Voice Emotion Recognition using Classical Machine Learning
This project classifies human emotions (like happy, sad, angry, calm) based on voice using classical Machine Learning (SVM). It includes training on .wav audio files, testing, live voice recording for prediction, and result visualization with charts.

âœ… Features
Extracts MFCC features from .wav files using librosa
Uses StandardScaler and trains an SVM classifier
Supports live voice input for real-time emotion prediction
Displays predictions using pie charts
Saves and loads the trained model using joblib
ğŸ“ Folder & Dataset Structure
Project Folder/
â”œâ”€â”€ train.py                # Main script for training and prediction
â”œâ”€â”€ Sound recordings/       # Folder containing labeled .wav files
â”‚   â”œâ”€â”€ happy_1.wav
â”‚   â”œâ”€â”€ sad_2.wav
â”‚   â”œâ”€â”€ calm_3.wav
â”‚   â””â”€â”€ angry_4.wav
Ensure file names start with the emotion label (e.g., happy_1.wav, sad_2.wav).

ğŸ’» Requirements
Install the required libraries with:

pip install numpy librosa scikit-learn matplotlib sounddevice soundfile joblib
ğŸš€ How to Run
python train.py
This will:

Extract features from the dataset
Train an SVM model
Save the model to svmodel.pkl
Record live voice twice
Predict emotion from live input
Show a pie chart of results
ğŸ“Š Example Output
âœ… Processed: happy_1.wav -> happy
âœ… Processed: sad_2.wav -> sad
ğŸ¯ Model Accuracy: 91.00%
ğŸ¤ Speak now... (Recording 1)
ğŸ§  Predicted Emotion: HAPPY
ğŸ¤ Speak now... (Recording 2)
ğŸ§  Predicted Emotion: SAD
ğŸ¤– Technologies Used
Python
Librosa â€“ audio feature extraction
scikit-learn â€“ SVM, pipeline, accuracy
Matplotlib â€“ visualization
sounddevice, soundfile â€“ for live voice recording
ğŸ‘©â€ğŸ’» Author
Nimra Fatima AI Researcher | Python & ML Developer
ğŸ”— GitHub: [https://github.com/Nimra71?tab=repositories] | LinkedIn: [https://www.linkedin.com/in/nimra-fatima-b67760333?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app]
